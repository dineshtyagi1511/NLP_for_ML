{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing for NLP\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Text Preprocessing](#introduction)\n",
    "2. [Basic Terminology](#terminology)\n",
    "3. [Tokenization](#tokenization)\n",
    "   - Word Tokenization\n",
    "   - Sentence Tokenization\n",
    "   - Custom Tokenization\n",
    "4. [Text Normalization](#normalization)\n",
    "   - Lowercasing\n",
    "   - Removing Special Characters\n",
    "   - Handling Numbers\n",
    "5. [Stemming](#stemming)\n",
    "   - Porter Stemmer\n",
    "   - Snowball Stemmer\n",
    "   - Lancaster Stemmer\n",
    "6. [Lemmatization](#lemmatization)\n",
    "7. [Stopwords Removal](#stopwords)\n",
    "8. [Complete Preprocessing Pipeline](#pipeline)\n",
    "9. [Real-World Example](#real-world)\n",
    "10. [Best Practices](#best-practices)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Text Preprocessing <a id='introduction'></a>\n",
    "\n",
    "**Text preprocessing** is the crucial first step in any NLP pipeline. It involves transforming raw text into a clean, standardized format that machines can process effectively.\n",
    "\n",
    "### Why is Preprocessing Important?\n",
    "\n",
    "1. **Reduces Noise**: Removes irrelevant information\n",
    "2. **Standardizes Text**: Ensures consistency (e.g., \"Running\", \"running\", \"run\" become similar)\n",
    "3. **Reduces Vocabulary Size**: Makes models more efficient\n",
    "4. **Improves Model Performance**: Clean data = better predictions\n",
    "\n",
    "### Raw Text Challenges:\n",
    "\n",
    "```python\n",
    "\"The QUICK brown fox!!! Jumped over the lazy dog... #amazing\"\n",
    "```\n",
    "\n",
    "Issues:\n",
    "- Mixed case (\"QUICK\" vs \"quick\")\n",
    "- Punctuation (!!!, ...)\n",
    "- Special characters (#)\n",
    "- Different word forms (\"Jumped\" vs \"jump\")\n",
    "- Stopwords (\"the\", \"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import necessary libraries\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLTK imports\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, TreebankWordTokenizer, WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Terminology <a id='terminology'></a>\n",
    "\n",
    "Before we dive into preprocessing techniques, let's understand key NLP terms:\n",
    "\n",
    "### Core Concepts:\n",
    "\n",
    "| Term | Definition | Example |\n",
    "|------|------------|----------|\n",
    "| **Corpus** | Collection of text documents | All Shakespeare plays |\n",
    "| **Document** | Single piece of text | One Shakespeare play |\n",
    "| **Token** | Individual unit of text | A word or punctuation mark |\n",
    "| **Vocabulary** | Set of unique tokens | {\"hello\", \"world\", \"nlp\"} |\n",
    "| **Lexicon** | Dictionary of words with meanings | English dictionary |\n",
    "| **Stopwords** | Common words with little meaning | \"the\", \"is\", \"at\", \"which\" |\n",
    "| **Stem** | Root form of a word (may not be valid) | \"running\" → \"run\" |\n",
    "| **Lemma** | Base dictionary form of a word | \"better\" → \"good\" |\n",
    "| **N-gram** | Sequence of N consecutive tokens | \"New York\" (bigram) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS (3 documents):\n",
      "  Document 1: Natural Language Processing is fascinating.\n",
      "  Document 2: Machine Learning powers modern AI applications.\n",
      "  Document 3: Text preprocessing is the first step in NLP.\n",
      "\n",
      "DOCUMENT: Natural Language Processing is fascinating.\n",
      "TOKENS: ['Natural', 'Language', 'Processing', 'is', 'fascinating', '.']\n",
      "Number of tokens: 6\n",
      "\n",
      "VOCABULARY SIZE: 19 unique tokens\n",
      "VOCABULARY: ['.', 'ai', 'applications', 'fascinating', 'first', 'in', 'is', 'language', 'learning', 'machine', 'modern', 'natural', 'nlp', 'powers', 'preprocessing', 'processing', 'step', 'text', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Example: Demonstrating basic terminology\n",
    "\n",
    "# Corpus: Collection of documents\n",
    "corpus = [\n",
    "    \"Natural Language Processing is fascinating.\",\n",
    "    \"Machine Learning powers modern AI applications.\",\n",
    "    \"Text preprocessing is the first step in NLP.\"\n",
    "]\n",
    "\n",
    "print(\"CORPUS (3 documents):\")\n",
    "for i, doc in enumerate(corpus, 1):\n",
    "    print(f\"  Document {i}: {doc}\")\n",
    "\n",
    "# Tokenize the first document\n",
    "document = corpus[0]\n",
    "tokens = word_tokenize(document)\n",
    "\n",
    "print(f\"\\nDOCUMENT: {document}\")\n",
    "print(f\"TOKENS: {tokens}\")\n",
    "print(f\"Number of tokens: {len(tokens)}\")\n",
    "\n",
    "# Get all unique tokens (vocabulary) from entire corpus\n",
    "all_tokens = []\n",
    "for doc in corpus:\n",
    "    all_tokens.extend(word_tokenize(doc.lower()))\n",
    "\n",
    "vocabulary = set(all_tokens)\n",
    "print(f\"\\nVOCABULARY SIZE: {len(vocabulary)} unique tokens\")\n",
    "print(f\"VOCABULARY: {sorted(vocabulary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization <a id='tokenization'></a>\n",
    "\n",
    "**Tokenization** is the process of breaking text into smaller units called **tokens**.\n",
    "\n",
    "### Types of Tokenization:\n",
    "1. **Word Tokenization**: Split text into words\n",
    "2. **Sentence Tokenization**: Split text into sentences\n",
    "3. **Character Tokenization**: Split text into characters\n",
    "4. **Subword Tokenization**: Split words into meaningful subunits\n",
    "\n",
    "### Why Tokenization Matters:\n",
    "- First step in text analysis\n",
    "- Determines granularity of analysis\n",
    "- Affects vocabulary size and model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Word Tokenization\n",
    "\n",
    "Split text into individual words (and punctuation marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT:\n",
      "Dr. Smith's research on AI (Artificial Intelligence) is groundbreaking! \n",
      "He said, \"NLP is the future.\" Visit https://example.com for more info.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "1. NLTK word_tokenize (Penn Treebank):\n",
      "   Tokens: ['Dr.', 'Smith', \"'s\", 'research', 'on', 'AI', '(', 'Artificial', 'Intelligence', ')', 'is', 'groundbreaking', '!', 'He', 'said', ',', '``', 'NLP', 'is', 'the', 'future', '.', \"''\", 'Visit', 'https', ':', '//example.com', 'for', 'more', 'info', '.']\n",
      "   Count: 31 tokens\n",
      "\n",
      "2. TreebankWordTokenizer:\n",
      "   Tokens: ['Dr.', 'Smith', \"'s\", 'research', 'on', 'AI', '(', 'Artificial', 'Intelligence', ')', 'is', 'groundbreaking', '!', 'He', 'said', ',', '``', 'NLP', 'is', 'the', 'future.', \"''\", 'Visit', 'https', ':', '//example.com', 'for', 'more', 'info', '.']\n",
      "   Count: 30 tokens\n",
      "\n",
      "3. WordPunctTokenizer:\n",
      "   Tokens: ['Dr', '.', 'Smith', \"'\", 's', 'research', 'on', 'AI', '(', 'Artificial', 'Intelligence', ')', 'is', 'groundbreaking', '!', 'He', 'said', ',', '\"', 'NLP', 'is', 'the', 'future', '.\"', 'Visit', 'https', '://', 'example', '.', 'com', 'for', 'more', 'info', '.']\n",
      "   Count: 34 tokens\n",
      "\n",
      "4. Simple split() [NOT RECOMMENDED]:\n",
      "   Tokens: ['Dr.', \"Smith's\", 'research', 'on', 'AI', '(Artificial', 'Intelligence)', 'is', 'groundbreaking!', 'He', 'said,', '\"NLP', 'is', 'the', 'future.\"', 'Visit', 'https://example.com', 'for', 'more', 'info.']\n",
      "   Count: 20 tokens\n",
      "\n",
      "5. spaCy tokenizer:\n",
      "   Tokens: ['Dr.', 'Smith', \"'s\", 'research', 'on', 'AI', '(', 'Artificial', 'Intelligence', ')', 'is', 'groundbreaking', '!', '\\n', 'He', 'said', ',', '\"', 'NLP', 'is', 'the', 'future', '.', '\"', 'Visit', 'https://example.com', 'for', 'more', 'info', '.']\n",
      "   Count: 30 tokens\n"
     ]
    }
   ],
   "source": [
    "# Example text with various challenges\n",
    "text = \"\"\"Dr. Smith's research on AI (Artificial Intelligence) is groundbreaking! \n",
    "He said, \\\"NLP is the future.\\\" Visit https://example.com for more info.\"\"\"\n",
    "\n",
    "print(\"ORIGINAL TEXT:\")\n",
    "print(text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Method 1: NLTK's word_tokenize (most common)\n",
    "# Uses Penn Treebank tokenization conventions\n",
    "tokens_nltk = word_tokenize(text)\n",
    "print(\"1. NLTK word_tokenize (Penn Treebank):\")\n",
    "print(f\"   Tokens: {tokens_nltk}\")\n",
    "print(f\"   Count: {len(tokens_nltk)} tokens\\n\")\n",
    "\n",
    "# Method 2: TreebankWordTokenizer (explicit Penn Treebank)\n",
    "tokenizer_treebank = TreebankWordTokenizer()\n",
    "tokens_treebank = tokenizer_treebank.tokenize(text)\n",
    "print(\"2. TreebankWordTokenizer:\")\n",
    "print(f\"   Tokens: {tokens_treebank}\")\n",
    "print(f\"   Count: {len(tokens_treebank)} tokens\\n\")\n",
    "\n",
    "# Method 3: WordPunctTokenizer (splits all punctuation)\n",
    "tokenizer_punct = WordPunctTokenizer()\n",
    "tokens_punct = tokenizer_punct.tokenize(text)\n",
    "print(\"3. WordPunctTokenizer:\")\n",
    "print(f\"   Tokens: {tokens_punct}\")\n",
    "print(f\"   Count: {len(tokens_punct)} tokens\\n\")\n",
    "\n",
    "# Method 4: Simple split by whitespace (naive approach)\n",
    "tokens_split = text.split()\n",
    "print(\"4. Simple split() [NOT RECOMMENDED]:\")\n",
    "print(f\"   Tokens: {tokens_split}\")\n",
    "print(f\"   Count: {len(tokens_split)} tokens\\n\")\n",
    "\n",
    "# Method 5: spaCy tokenizer (modern approach)\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])  # Load only tokenizer\n",
    "doc = nlp(text)\n",
    "tokens_spacy = [token.text for token in doc]\n",
    "print(\"5. spaCy tokenizer:\")\n",
    "print(f\"   Tokens: {tokens_spacy}\")\n",
    "print(f\"   Count: {len(tokens_spacy)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sentence Tokenization\n",
    "\n",
    "Split text into sentences - useful for tasks like summarization and machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL PARAGRAPH:\n",
      "Natural Language Processing is a subfield of AI. It focuses on the \n",
      "interaction between computers and humans. Dr. Johnson's research showed promising \n",
      "results! However, challenges remain... What will the future hold? We'll find out soon.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "NLTK Sentence Tokenization:\n",
      "Number of sentences: 5\n",
      "\n",
      "Sentence 1: Natural Language Processing is a subfield of AI.\n",
      "Sentence 2: It focuses on the \n",
      "interaction between computers and humans.\n",
      "Sentence 3: Dr. Johnson's research showed promising \n",
      "results!\n",
      "Sentence 4: However, challenges remain... What will the future hold?\n",
      "Sentence 5: We'll find out soon.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example paragraph with multiple sentences\n",
    "paragraph = \"\"\"Natural Language Processing is a subfield of AI. It focuses on the \n",
    "interaction between computers and humans. Dr. Johnson's research showed promising \n",
    "results! However, challenges remain... What will the future hold? We'll find out soon.\"\"\"\n",
    "\n",
    "print(\"ORIGINAL PARAGRAPH:\")\n",
    "print(paragraph)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# NLTK sentence tokenization\n",
    "# Handles abbreviations like \"Dr.\" correctly\n",
    "sentences_nltk = sent_tokenize(paragraph)\n",
    "\n",
    "print(\"NLTK Sentence Tokenization:\")\n",
    "print(f\"Number of sentences: {len(sentences_nltk)}\\n\")\n",
    "\n",
    "for i, sentence in enumerate(sentences_nltk, 1):\n",
    "    print(f\"Sentence {i}: {sentence.strip()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Sentence Tokenization:\n",
      "Number of sentences: 6\n",
      "\n",
      "Sentence 1: Natural Language Processing is a subfield of AI.\n",
      "Sentence 2: It focuses on the \n",
      "interaction between computers and humans.\n",
      "Sentence 3: Dr. Johnson's research showed promising \n",
      "results!\n",
      "Sentence 4: However, challenges remain...\n",
      "Sentence 5: What will the future hold?\n",
      "Sentence 6: We'll find out soon.\n"
     ]
    }
   ],
   "source": [
    "# Spacy sentence tokenization\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")   # or spacy.blank(\"en\")\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"sentencizer\")      # adds rule-based sentence boundary detection\n",
    "\n",
    "doc = nlp(paragraph)\n",
    "sentences_spacy = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "print(\"spaCy Sentence Tokenization:\")\n",
    "print(f\"Number of sentences: {len(sentences_spacy)}\\n\")\n",
    "\n",
    "for i, sentence in enumerate(sentences_spacy, 1):\n",
    "    print(f\"Sentence {i}: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Custom Tokenization with Regular Expressions\n",
    "\n",
    "For specialized tasks, you might need custom tokenization rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT:\n",
      "Contact me at john.doe@email.com or call +1-555-123-4567. Price: $99.99!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "1. Words only (no punctuation/numbers):\n",
      "   ['Contact', 'me', 'at', 'john', 'doe', 'email', 'com', 'or', 'call', 'Price']\n",
      "\n",
      "2. Words and numbers:\n",
      "   ['Contact', 'me', 'at', 'john', 'doe', 'email', 'com', 'or', 'call', '1', '555', '123', '4567', 'Price', '99', '99']\n",
      "\n",
      "3. Email addresses:\n",
      "   ['john.doe@email.com']\n",
      "\n",
      "4. Phone numbers:\n",
      "   ['+1-555-123-4567']\n",
      "\n",
      "5. Prices:\n",
      "   ['$99.99']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Contact me at john.doe@email.com or call +1-555-123-4567. Price: $99.99!\"\n",
    "\n",
    "print(\"ORIGINAL TEXT:\")\n",
    "print(text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Custom tokenizer 1: Extract only words (no punctuation or numbers)\n",
    "words_only = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "print(\"1. Words only (no punctuation/numbers):\")\n",
    "print(f\"   {words_only}\\n\")\n",
    "\n",
    "# Custom tokenizer 2: Extract words and numbers\n",
    "words_and_numbers = re.findall(r'\\b\\w+\\b', text)\n",
    "print(\"2. Words and numbers:\")\n",
    "print(f\"   {words_and_numbers}\\n\")\n",
    "\n",
    "# Custom tokenizer 3: Extract emails\n",
    "emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "print(\"3. Email addresses:\")\n",
    "print(f\"   {emails}\\n\")\n",
    "\n",
    "# Custom tokenizer 4: Extract phone numbers\n",
    "phones = re.findall(r'\\+?\\d[\\d -]{8,}\\d', text)\n",
    "print(\"4. Phone numbers:\")\n",
    "print(f\"   {phones}\\n\")\n",
    "\n",
    "# Custom tokenizer 5: Extract prices\n",
    "prices = re.findall(r'\\$\\d+\\.\\d{2}', text)\n",
    "print(\"5. Prices:\")\n",
    "print(f\"   {prices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Normalization <a id='normalization'></a>\n",
    "\n",
    "Text normalization standardizes text to reduce variations and improve consistency.\n",
    "\n",
    "### Common Normalization Techniques:\n",
    "1. Lowercasing\n",
    "2. Removing special characters\n",
    "3. Removing or handling numbers\n",
    "4. Removing extra whitespace\n",
    "5. Handling contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT:\n",
      "'   The PRICE is $299.99!!!   \\nI can\\'t believe it\\'s THIS cheap... @JohnDoe said: \"Amazing deal!\"   \\nVisit us @ https://example.com     #Sale2024   '\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Step 1 - Remove extra whitespace:\n",
      "'The PRICE is $299.99!!! I can\\'t believe it\\'s THIS cheap... @JohnDoe said: \"Amazing deal!\" Visit us @ https://example.com #Sale2024'\n",
      "\n",
      "Step 2 - Lowercase:\n",
      "'the price is $299.99!!! i can\\'t believe it\\'s this cheap... @johndoe said: \"amazing deal!\" visit us @ https://example.com #sale2024'\n",
      "\n",
      "Step 3 - Remove URLs:\n",
      "'the price is $299.99!!! i can\\'t believe it\\'s this cheap... @johndoe said: \"amazing deal!\" visit us @  #sale2024'\n",
      "\n",
      "Step 4 - Remove mentions and hashtags:\n",
      "'the price is $299.99!!! i can\\'t believe it\\'s this cheap...  said: \"amazing deal!\" visit us @  '\n",
      "\n",
      "Step 5 - Remove special characters:\n",
      "'the price is 299.99!!! i can\\'t believe it\\'s this cheap...  said \"amazing deal!\" visit us   '\n",
      "\n",
      "Step 6 - Remove numbers (optional):\n",
      "'the price is .!!! i can\\'t believe it\\'s this cheap...  said \"amazing deal!\" visit us   '\n"
     ]
    }
   ],
   "source": [
    "# Example text with normalization challenges\n",
    "messy_text = \"\"\"   The PRICE is $299.99!!!   \n",
    "I can't believe it's THIS cheap... @JohnDoe said: \\\"Amazing deal!\\\"   \n",
    "Visit us @ https://example.com     #Sale2024   \"\"\"\n",
    "\n",
    "print(\"ORIGINAL TEXT:\")\n",
    "print(repr(messy_text))  # repr shows special characters\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Step 1: Remove extra whitespace and newlines\n",
    "text = ' '.join(messy_text.split())\n",
    "print(\"Step 1 - Remove extra whitespace:\")\n",
    "print(repr(text))\n",
    "print()\n",
    "\n",
    "# Step 2: Convert to lowercase\n",
    "text = text.lower()\n",
    "print(\"Step 2 - Lowercase:\")\n",
    "print(repr(text))\n",
    "print()\n",
    "\n",
    "# Step 3: Remove URLs\n",
    "text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "print(\"Step 3 - Remove URLs:\")\n",
    "print(repr(text))\n",
    "print()\n",
    "\n",
    "# Step 4: Remove mentions and hashtags\n",
    "text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "print(\"Step 4 - Remove mentions and hashtags:\")\n",
    "print(repr(text))\n",
    "print()\n",
    "\n",
    "# Step 5: Remove special characters (keep only letters, numbers, and basic punctuation)\n",
    "text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\\\"]+', '', text)\n",
    "print(\"Step 5 - Remove special characters:\")\n",
    "print(repr(text))\n",
    "print()\n",
    "\n",
    "# Step 6: Remove numbers (optional - depends on your use case)\n",
    "text_no_numbers = re.sub(r'\\d+', '', text)\n",
    "print(\"Step 6 - Remove numbers (optional):\")\n",
    "print(repr(text_no_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing normalization function:\n",
      "\n",
      "Original:    Check out https://example.com for #AmazingDeals!!! @JohnDoe\n",
      "Normalized:  check out for\n",
      "\n",
      "Original:    The price is $99.99 (was $199.99)... WOW!!!\n",
      "Normalized:  the price is 9999 was 19999 wow\n",
      "\n",
      "Original:    Contact: info@company.com or call 555-1234\n",
      "Normalized:  contact infocom or call 5551234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive normalization function\n",
    "\n",
    "def normalize_text(text, \n",
    "                   lowercase=True,\n",
    "                   remove_urls=True,\n",
    "                   remove_mentions=True,\n",
    "                   remove_hashtags=True,\n",
    "                   remove_special_chars=True,\n",
    "                   remove_numbers=False,\n",
    "                   remove_extra_whitespace=True):\n",
    "    \"\"\"\n",
    "    Comprehensive text normalization function.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to normalize\n",
    "        lowercase (bool): Convert to lowercase\n",
    "        remove_urls (bool): Remove URLs\n",
    "        remove_mentions (bool): Remove @mentions\n",
    "        remove_hashtags (bool): Remove #hashtags\n",
    "        remove_special_chars (bool): Remove special characters\n",
    "        remove_numbers (bool): Remove numbers\n",
    "        remove_extra_whitespace (bool): Remove extra spaces\n",
    "    \n",
    "    Returns:\n",
    "        str: Normalized text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove extra whitespace and newlines\n",
    "    if remove_extra_whitespace:\n",
    "        text = ' '.join(text.split())\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    if remove_urls:\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    if remove_mentions:\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    if remove_hashtags:\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    if remove_special_chars:\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Final whitespace cleanup\n",
    "    if remove_extra_whitespace:\n",
    "        text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the function\n",
    "test_texts = [\n",
    "    \"Check out https://example.com for #AmazingDeals!!! @JohnDoe\",\n",
    "    \"The price is $99.99 (was $199.99)... WOW!!!\",\n",
    "    \"Contact: info@company.com or call 555-1234\"\n",
    "]\n",
    "\n",
    "print(\"Testing normalization function:\\n\")\n",
    "for text in test_texts:\n",
    "    normalized = normalize_text(text, remove_numbers=False)\n",
    "    print(f\"Original:    {text}\")\n",
    "    print(f\"Normalized:  {normalized}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stemming <a id='stemming'></a>\n",
    "\n",
    "**Stemming** reduces words to their root/base form by removing suffixes.\n",
    "\n",
    "### How Stemming Works:\n",
    "- Uses rule-based algorithms\n",
    "- Chops off word endings\n",
    "- **Fast** but sometimes **inaccurate**\n",
    "- Result may not be a valid word\n",
    "\n",
    "### Examples:\n",
    "- \"running\" → \"run\"\n",
    "- \"flies\" → \"fli\"\n",
    "- \"better\" → \"better\" (not \"good\")\n",
    "\n",
    "### Popular Stemmers:\n",
    "1. **Porter Stemmer**: Most common, moderate aggressiveness\n",
    "2. **Snowball Stemmer**: Improved Porter, supports multiple languages\n",
    "3. **Lancaster Stemmer**: Most aggressive, can over-stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Different Stemmers:\n",
      "\n",
      "   Original  Porter Snowball Lancaster\n",
      "    running     run      run       run\n",
      "       runs     run      run       run\n",
      "        ran     ran      ran       ran\n",
      "     runner  runner   runner       run\n",
      "    happily happili  happili     happy\n",
      "  happiness   happi    happi     happy\n",
      "      happy   happi    happi     happy\n",
      " connection connect  connect   connect\n",
      "  connected connect  connect   connect\n",
      " connecting connect  connect   connect\n",
      "   connects connect  connect   connect\n",
      "    studies   studi    studi     study\n",
      "   studying   studi    studi     study\n",
      "    studied   studi    studi     study\n",
      " generously   gener generous       gen\n",
      "   generous   gener generous       gen\n",
      " generosity generos  generos   generos\n",
      "   probably probabl  probabl      prob\n",
      "   probable probabl  probabl      prob\n",
      "probability probabl  probabl      prob\n"
     ]
    }
   ],
   "source": [
    "# Initialize different stemmers\n",
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "# Test words with different forms\n",
    "words = [\n",
    "    'running', 'runs', 'ran', 'runner',\n",
    "    'happily', 'happiness', 'happy',\n",
    "    'connection', 'connected', 'connecting', 'connects',\n",
    "    'studies', 'studying', 'studied',\n",
    "    'generously', 'generous', 'generosity',\n",
    "    'probably', 'probable', 'probability'\n",
    "]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "stemming_results = []\n",
    "\n",
    "for word in words:\n",
    "    stemming_results.append({\n",
    "        'Original': word,\n",
    "        'Porter': porter.stem(word),\n",
    "        'Snowball': snowball.stem(word),\n",
    "        'Lancaster': lancaster.stem(word)\n",
    "    })\n",
    "\n",
    "df_stemming = pd.DataFrame(stemming_results)\n",
    "\n",
    "print(\"Comparison of Different Stemmers:\\n\")\n",
    "print(df_stemming.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL SENTENCE:\n",
      "The runners were running happily through the connected pathways.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Tokens: ['the', 'runners', 'were', 'running', 'happily', 'through', 'the', 'connected', 'pathways', '.']\n",
      "\n",
      "Porter Stemmer:\n",
      "Stemmed tokens: ['the', 'runner', 'were', 'run', 'happili', 'through', 'the', 'connect', 'pathway', '.']\n",
      "Reconstructed: the runner were run happili through the connect pathway .\n",
      "\n",
      "Snowball Stemmer:\n",
      "Stemmed tokens: ['the', 'runner', 'were', 'run', 'happili', 'through', 'the', 'connect', 'pathway', '.']\n",
      "Reconstructed: the runner were run happili through the connect pathway .\n",
      "\n",
      "Lancaster Stemmer:\n",
      "Stemmed tokens: ['the', 'run', 'wer', 'run', 'happy', 'through', 'the', 'connect', 'pathway', '.']\n",
      "Reconstructed: the run wer run happy through the connect pathway .\n"
     ]
    }
   ],
   "source": [
    "# Practical example: Stem a sentence\n",
    "\n",
    "sentence = \"The runners were running happily through the connected pathways.\"\n",
    "\n",
    "print(\"ORIGINAL SENTENCE:\")\n",
    "print(sentence)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tokenize first\n",
    "tokens = word_tokenize(sentence.lower())\n",
    "print(f\"Tokens: {tokens}\\n\")\n",
    "\n",
    "# Apply Porter Stemmer\n",
    "stemmed_porter = [porter.stem(token) for token in tokens]\n",
    "print(\"Porter Stemmer:\")\n",
    "print(f\"Stemmed tokens: {stemmed_porter}\")\n",
    "print(f\"Reconstructed: {' '.join(stemmed_porter)}\")\n",
    "print()\n",
    "\n",
    "# Apply Snowball Stemmer\n",
    "stemmed_snowball = [snowball.stem(token) for token in tokens]\n",
    "print(\"Snowball Stemmer:\")\n",
    "print(f\"Stemmed tokens: {stemmed_snowball}\")\n",
    "print(f\"Reconstructed: {' '.join(stemmed_snowball)}\")\n",
    "print()\n",
    "\n",
    "# Apply Lancaster Stemmer\n",
    "stemmed_lancaster = [lancaster.stem(token) for token in tokens]\n",
    "print(\"Lancaster Stemmer:\")\n",
    "print(f\"Stemmed tokens: {stemmed_lancaster}\")\n",
    "print(f\"Reconstructed: {' '.join(stemmed_lancaster)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with Stemming\n",
    "\n",
    "Stemming can be too aggressive or miss important distinctions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Stemming Issues:\n",
      "\n",
      "Word            Porter          Snowball        Lancaster      \n",
      "============================================================\n",
      "university      univers         univers         univers        \n",
      "universe        univers         univers         univers        \n",
      "universal       univers         univers         univers        \n",
      "better          better          better          bet            \n",
      "good            good            good            good           \n",
      "caring          care            care            car            \n",
      "car             car             car             car            \n",
      "news            news            news            new            \n",
      "new             new             new             new            \n",
      "studies         studi           studi           study          \n",
      "study           studi           studi           study          \n"
     ]
    }
   ],
   "source": [
    "# Examples of stemming issues\n",
    "\n",
    "problematic_words = [\n",
    "    'university', 'universe', 'universal',  # Different meanings, same stem\n",
    "    'better', 'good',  # Should have same meaning, different stems\n",
    "    'caring', 'car',  # 'caring' stems to 'car' in some stemmers\n",
    "    'news', 'new',  # Different meanings\n",
    "    'studies', 'study',  # Related but different forms\n",
    "]\n",
    "\n",
    "print(\"Potential Stemming Issues:\\n\")\n",
    "print(f\"{'Word':<15} {'Porter':<15} {'Snowball':<15} {'Lancaster':<15}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for word in problematic_words:\n",
    "    print(f\"{word:<15} {porter.stem(word):<15} {snowball.stem(word):<15} {lancaster.stem(word):<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lemmatization <a id='lemmatization'></a>\n",
    "\n",
    "**Lemmatization** reduces words to their dictionary base form (lemma) using vocabulary and morphological analysis.\n",
    "\n",
    "### Lemmatization vs Stemming:\n",
    "\n",
    "| Aspect | Stemming | Lemmatization |\n",
    "|--------|----------|---------------|\n",
    "| **Method** | Rule-based chopping | Dictionary lookup + morphology |\n",
    "| **Speed** | Fast | Slower |\n",
    "| **Accuracy** | Lower | Higher |\n",
    "| **Output** | May not be real word | Always a valid word |\n",
    "| **Example** | \"studies\" → \"studi\" | \"studies\" → \"study\" |\n",
    "| **Example** | \"better\" → \"better\" | \"better\" → \"good\" |\n",
    "\n",
    "### When to Use What:\n",
    "- **Stemming**: Speed is critical, approximate matching is okay (e.g., search engines)\n",
    "- **Lemmatization**: Accuracy is important, need valid words (e.g., chatbots, translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming vs Lemmatization Comparison:\n",
      "\n",
      "Word            Porter Stem     Lemma          \n",
      "=============================================\n",
      "running         run             running        \n",
      "runs            run             run            \n",
      "ran             ran             ran            \n",
      "better          better          better         \n",
      "best            best            best           \n",
      "good            good            good           \n",
      "caring          care            caring         \n",
      "cared           care            cared          \n",
      "cares           care            care           \n",
      "studies         studi           study          \n",
      "studying        studi           studying       \n",
      "studied         studi           studied        \n",
      "mice            mice            mouse          \n",
      "geese           gees            goose          \n",
      "children        children        child          \n",
      "was             wa              wa             \n",
      "is              is              is             \n",
      "are             are             are            \n",
      "been            been            been           \n"
     ]
    }
   ],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Test words\n",
    "test_words = [\n",
    "    'running', 'runs', 'ran',\n",
    "    'better', 'best', 'good',\n",
    "    'caring', 'cared', 'cares',\n",
    "    'studies', 'studying', 'studied',\n",
    "    'mice', 'geese', 'children',\n",
    "    'was', 'is', 'are', 'been',\n",
    "]\n",
    "\n",
    "print(\"Stemming vs Lemmatization Comparison:\\n\")\n",
    "print(f\"{'Word':<15} {'Porter Stem':<15} {'Lemma':<15}\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "for word in test_words:\n",
    "    stem = porter.stem(word)\n",
    "    lemma = lemmatizer.lemmatize(word)\n",
    "    print(f\"{word:<15} {stem:<15} {lemma:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-aware Lemmatization\n",
    "\n",
    "Lemmatization works better when we provide the Part-of-Speech (POS) tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'better'\n",
      "\n",
      "Without POS: better\n",
      "As adjective: good\n",
      "\n",
      "============================================================\n",
      "\n",
      "Word            POS        Lemma          \n",
      "========================================\n",
      "running         verb       run            \n",
      "running         noun       running        \n",
      "better          adjective  good           \n",
      "caring          verb       care           \n",
      "caring          adjective  caring         \n"
     ]
    }
   ],
   "source": [
    "# Example showing importance of POS tags in lemmatization\n",
    "\n",
    "word = \"better\"\n",
    "\n",
    "print(f\"Word: '{word}'\\n\")\n",
    "\n",
    "# Without POS tag (defaults to noun)\n",
    "lemma_default = lemmatizer.lemmatize(word)\n",
    "print(f\"Without POS: {lemma_default}\")\n",
    "\n",
    "# With POS tag as adjective\n",
    "lemma_adj = lemmatizer.lemmatize(word, pos='a')  # 'a' for adjective\n",
    "print(f\"As adjective: {lemma_adj}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# More examples\n",
    "examples = [\n",
    "    ('running', 'v'),  # verb\n",
    "    ('running', 'n'),  # noun\n",
    "    ('better', 'a'),   # adjective\n",
    "    ('caring', 'v'),   # verb\n",
    "    ('caring', 'a'),   # adjective\n",
    "]\n",
    "\n",
    "print(f\"{'Word':<15} {'POS':<10} {'Lemma':<15}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for word, pos in examples:\n",
    "    lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "    pos_name = {'v': 'verb', 'n': 'noun', 'a': 'adjective'}[pos]\n",
    "    print(f\"{word:<15} {pos_name:<10} {lemma:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: The striped bats are hanging on their feet for best sleep.\n",
      "\n",
      "Tokens: ['the', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best', 'sleep', '.']\n",
      "\n",
      "Lemmatized (no POS): ['the', 'striped', 'bat', 'are', 'hanging', 'on', 'their', 'foot', 'for', 'best', 'sleep', '.']\n",
      "\n",
      "Lemmatized (with POS): ['the', 'striped', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best', 'sleep', '.']\n"
     ]
    }
   ],
   "source": [
    "# Automatic POS tagging + Lemmatization\n",
    "from nltk import pos_tag\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    Convert Penn Treebank POS tags to WordNet POS tags.\n",
    "    WordNet uses: 'n' (noun), 'v' (verb), 'a' (adjective), 'r' (adverb)\n",
    "    \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'  # adjective\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'v'  # verb\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'n'  # noun\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'r'  # adverb\n",
    "    else:\n",
    "        return 'n'  # default to noun\n",
    "\n",
    "def lemmatize_with_pos(text):\n",
    "    \"\"\"\n",
    "    Lemmatize text with automatic POS tagging.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text\n",
    "    \n",
    "    Returns:\n",
    "        list: List of lemmatized tokens\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # POS tag\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Lemmatize with POS\n",
    "    lemmatized = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(pos)) \n",
    "        for word, pos in pos_tags\n",
    "    ]\n",
    "    \n",
    "    return lemmatized\n",
    "\n",
    "# Test the function\n",
    "sentence = \"The striped bats are hanging on their feet for best sleep.\"\n",
    "\n",
    "print(\"SENTENCE:\", sentence)\n",
    "print(\"\\nTokens:\", word_tokenize(sentence.lower()))\n",
    "print(\"\\nLemmatized (no POS):\", [lemmatizer.lemmatize(w) for w in word_tokenize(sentence.lower())])\n",
    "print(\"\\nLemmatized (with POS):\", lemmatize_with_pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stopwords Removal <a id='stopwords'></a>\n",
    "\n",
    "**Stopwords** are common words that typically don't carry much meaning:\n",
    "- Articles: \"a\", \"an\", \"the\"\n",
    "- Prepositions: \"in\", \"on\", \"at\"\n",
    "- Pronouns: \"I\", \"you\", \"he\", \"she\"\n",
    "- Conjunctions: \"and\", \"but\", \"or\"\n",
    "\n",
    "### Why Remove Stopwords?\n",
    "1. **Reduce vocabulary size**: Fewer unique words to process\n",
    "2. **Focus on meaningful words**: Improve signal-to-noise ratio\n",
    "3. **Improve performance**: Faster processing\n",
    "4. **Better features**: More discriminative features for ML\n",
    "\n",
    "### When NOT to Remove Stopwords:\n",
    "- Machine translation\n",
    "- Question answering (\"who\", \"what\", \"where\" are important)\n",
    "- Sentiment analysis (\"not\", \"but\" affect sentiment)\n",
    "- Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stopwords in NLTK English: 198\n",
      "\n",
      "Sample stopwords:\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn']\n",
      "\n",
      "============================================================\n",
      "\n",
      "Is it a stopword?\n",
      "\n",
      "  'the': True\n",
      "  'hello': False\n",
      "  'not': True\n",
      "  'python': False\n",
      "  'very': True\n",
      "  'computer': False\n"
     ]
    }
   ],
   "source": [
    "# Explore NLTK's English stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "print(f\"Total stopwords in NLTK English: {len(stop_words)}\\n\")\n",
    "\n",
    "# Display some stopwords\n",
    "print(\"Sample stopwords:\")\n",
    "print(sorted(list(stop_words))[:50])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Check specific words\n",
    "test_words = ['the', 'hello', 'not', 'python', 'very', 'computer']\n",
    "print(\"Is it a stopword?\\n\")\n",
    "for word in test_words:\n",
    "    is_stop = word in stop_words\n",
    "    print(f\"  '{word}': {is_stop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT:\n",
      "Natural Language Processing is a subfield of artificial intelligence \n",
      "that focuses on the interaction between computers and humans through natural language.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Total tokens: 22\n",
      "Tokens: ['natural', 'language', 'processing', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', '.']\n",
      "\n",
      "Tokens after stopword removal: 12\n",
      "Filtered: ['natural', 'language', 'processing', 'subfield', 'artificial', 'intelligence', 'focuses', 'interaction', 'computers', 'humans', 'natural', 'language']\n",
      "\n",
      "Removed words: ['is', 'a', 'of', 'that', 'on', 'the', 'between', 'and', 'through', '.']\n",
      "\n",
      "================================================================================\n",
      "\n",
      "RECONSTRUCTED TEXT (without stopwords):\n",
      "natural language processing subfield artificial intelligence focuses interaction computers humans natural language\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords from text\n",
    "\n",
    "text = \"\"\"Natural Language Processing is a subfield of artificial intelligence \n",
    "that focuses on the interaction between computers and humans through natural language.\"\"\"\n",
    "\n",
    "print(\"ORIGINAL TEXT:\")\n",
    "print(text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tokenize\n",
    "tokens = word_tokenize(text.lower())\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "print(f\"Tokens: {tokens}\\n\")\n",
    "\n",
    "# Remove stopwords and punctuation\n",
    "filtered_tokens = [\n",
    "    word for word in tokens \n",
    "    if word not in stop_words and word.isalpha()  # isalpha() removes punctuation\n",
    "]\n",
    "\n",
    "print(f\"Tokens after stopword removal: {len(filtered_tokens)}\")\n",
    "print(f\"Filtered: {filtered_tokens}\\n\")\n",
    "\n",
    "# Show removed words\n",
    "removed_words = [word for word in tokens if word not in filtered_tokens]\n",
    "print(f\"Removed words: {removed_words}\")\n",
    "\n",
    "# Reconstruct text\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"RECONSTRUCTED TEXT (without stopwords):\")\n",
    "print(' '.join(filtered_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Stopwords Configuration:\n",
      "\n",
      "Original NLTK stopwords: 198\n",
      "Added domain stopwords: 5\n",
      "Removed important words: 6\n",
      "Total custom stopwords: 200\n",
      "\n",
      "============================================================\n",
      "\n",
      "Original: This product is not good. I will never buy this item again.\n",
      "\n",
      "Standard stopwords: product good never buy item\n",
      "Custom stopwords:   not good never buy\n",
      "\n",
      "Notice: Custom version keeps 'not' and 'never' but removes 'product' and 'item'\n"
     ]
    }
   ],
   "source": [
    "# Custom stopwords list\n",
    "# Sometimes you need to add domain-specific stopwords\n",
    "\n",
    "# Start with NLTK stopwords\n",
    "custom_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Add domain-specific stopwords (e.g., for product reviews)\n",
    "domain_stops = {'product', 'item', 'purchase', 'bought', 'order'}\n",
    "custom_stopwords.update(domain_stops)\n",
    "\n",
    "# Or remove certain stopwords that might be important\n",
    "# (e.g., for sentiment analysis, keep negations)\n",
    "important_words = {'not', 'no', 'nor', 'neither', 'never', 'none'}\n",
    "custom_stopwords -= important_words  # Remove from stopwords\n",
    "\n",
    "print(\"Custom Stopwords Configuration:\\n\")\n",
    "print(f\"Original NLTK stopwords: {len(stopwords.words('english'))}\")\n",
    "print(f\"Added domain stopwords: {len(domain_stops)}\")\n",
    "print(f\"Removed important words: {len(important_words)}\")\n",
    "print(f\"Total custom stopwords: {len(custom_stopwords)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test with sentiment-bearing sentence\n",
    "review = \"This product is not good. I will never buy this item again.\"\n",
    "\n",
    "tokens = word_tokenize(review.lower())\n",
    "\n",
    "# With standard stopwords (removes 'not' and 'never')\n",
    "standard_filtered = [w for w in tokens if w not in stop_words and w.isalpha()]\n",
    "\n",
    "# With custom stopwords (keeps 'not' and 'never')\n",
    "custom_filtered = [w for w in tokens if w not in custom_stopwords and w.isalpha()]\n",
    "\n",
    "print(\"Original:\", review)\n",
    "print(f\"\\nStandard stopwords: {' '.join(standard_filtered)}\")\n",
    "print(f\"Custom stopwords:   {' '.join(custom_filtered)}\")\n",
    "print(\"\\nNotice: Custom version keeps 'not' and 'never' but removes 'product' and 'item'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complete Preprocessing Pipeline <a id='pipeline'></a>\n",
    "\n",
    "Let's combine everything into a comprehensive preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT:\n",
      "Hey @JohnDoe! Check out this AMAZING article on #NLP at \n",
      "https://example.com. I'm studying Machine Learning and it's fascinating! \n",
      "The researchers were running experiments with 1000+ datasets.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Minimal (just lowercase + tokenize):\n",
      "  hey check out this amazing article on at i studying machine learning and it fascinating the researchers were running experiments with datasets\n",
      "\n",
      "Standard (remove stopwords + lemmatize):\n",
      "  hey check amaze article study machine learn fascinating researcher run experiment datasets\n",
      "\n",
      "Aggressive (everything + stemming):\n",
      "  hey check amaz articl studi machin learn fascin research run experi dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text_pipeline(text, \n",
    "                             lowercase=True,\n",
    "                             remove_urls=True,\n",
    "                             remove_mentions=True,\n",
    "                             remove_hashtags=True,\n",
    "                             remove_numbers=False,\n",
    "                             remove_punctuation=True,\n",
    "                             remove_stopwords=True,\n",
    "                             stemming=False,\n",
    "                             lemmatization=True,\n",
    "                             use_pos_tagging=True):\n",
    "    \"\"\"\n",
    "    Complete text preprocessing pipeline.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text\n",
    "        lowercase (bool): Convert to lowercase\n",
    "        remove_urls (bool): Remove URLs\n",
    "        remove_mentions (bool): Remove @mentions\n",
    "        remove_hashtags (bool): Remove #hashtags\n",
    "        remove_numbers (bool): Remove numbers\n",
    "        remove_punctuation (bool): Remove punctuation\n",
    "        remove_stopwords (bool): Remove stopwords\n",
    "        stemming (bool): Apply stemming\n",
    "        lemmatization (bool): Apply lemmatization\n",
    "        use_pos_tagging (bool): Use POS tagging for lemmatization\n",
    "    \n",
    "    Returns:\n",
    "        str: Preprocessed text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Normalize whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Step 2: Remove URLs\n",
    "    if remove_urls:\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Step 3: Remove mentions and hashtags\n",
    "    if remove_mentions:\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "    if remove_hashtags:\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    # Step 4: Lowercase\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    # Step 5: Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Step 6: Remove numbers\n",
    "    if remove_numbers:\n",
    "        tokens = [token for token in tokens if not token.isdigit()]\n",
    "    \n",
    "    # Step 7: Remove punctuation\n",
    "    if remove_punctuation:\n",
    "        tokens = [token for token in tokens if token.isalnum()]\n",
    "    \n",
    "    # Step 8: Remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Step 9: Stemming or Lemmatization\n",
    "    if stemming:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    elif lemmatization:\n",
    "        if use_pos_tagging:\n",
    "            # POS-aware lemmatization\n",
    "            pos_tags = pos_tag(tokens)\n",
    "            tokens = [\n",
    "                lemmatizer.lemmatize(word, get_wordnet_pos(pos)) \n",
    "                for word, pos in pos_tags\n",
    "            ]\n",
    "        else:\n",
    "            # Simple lemmatization\n",
    "            tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Step 10: Join back to string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Test the pipeline\n",
    "test_text = \"\"\"Hey @JohnDoe! Check out this AMAZING article on #NLP at \n",
    "https://example.com. I'm studying Machine Learning and it's fascinating! \n",
    "The researchers were running experiments with 1000+ datasets.\"\"\"\n",
    "\n",
    "print(\"ORIGINAL TEXT:\")\n",
    "print(test_text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Apply preprocessing with different configurations\n",
    "configs = [\n",
    "    {\"name\": \"Minimal (just lowercase + tokenize)\", \n",
    "     \"params\": {\"remove_stopwords\": False, \"lemmatization\": False}},\n",
    "    \n",
    "    {\"name\": \"Standard (remove stopwords + lemmatize)\", \n",
    "     \"params\": {}},\n",
    "    \n",
    "    {\"name\": \"Aggressive (everything + stemming)\", \n",
    "     \"params\": {\"remove_numbers\": True, \"lemmatization\": False, \"stemming\": True}},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    result = preprocess_text_pipeline(test_text, **config[\"params\"])\n",
    "    print(f\"{config['name']}:\")\n",
    "    print(f\"  {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Real-World Example: Preprocessing Movie Reviews <a id='real-world'></a>\n",
    "\n",
    "Let's apply preprocessing to a realistic dataset of movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Reviews:\n",
      "================================================================================\n",
      "\n",
      "1. [POSITIVE]\n",
      "   This movie was ABSOLUTELY AMAZING!!! Best film I've seen in years! #MustWatch\n",
      "\n",
      "2. [NEGATIVE]\n",
      "   Terrible waste of time... The acting was horrible and the plot made no sense whatsoever.\n",
      "\n",
      "3. [NEUTRAL]\n",
      "   Pretty good overall, though the ending could've been better. I'd give it 7/10.\n",
      "\n",
      "4. [POSITIVE]\n",
      "   OMG!!! @DirectorName you've outdone yourself! This is PERFECTION! https://moviereview.com/review\n",
      "\n",
      "5. [NEUTRAL]\n",
      "   Not bad, not great. Just okay. Wouldn't watch it again but didn't hate it either.\n",
      "\n",
      "6. [NEUTRAL]\n",
      "   The cinematography was stunning! However, the storyline was quite predictable. Mixed feelings...\n"
     ]
    }
   ],
   "source": [
    "# Sample movie reviews (simulating real data)\n",
    "reviews = [\n",
    "    \"This movie was ABSOLUTELY AMAZING!!! Best film I've seen in years! #MustWatch\",\n",
    "    \"Terrible waste of time... The acting was horrible and the plot made no sense whatsoever.\",\n",
    "    \"Pretty good overall, though the ending could've been better. I'd give it 7/10.\",\n",
    "    \"OMG!!! @DirectorName you've outdone yourself! This is PERFECTION! https://moviereview.com/review\",\n",
    "    \"Not bad, not great. Just okay. Wouldn't watch it again but didn't hate it either.\",\n",
    "    \"The cinematography was stunning! However, the storyline was quite predictable. Mixed feelings...\"\n",
    "]\n",
    "\n",
    "sentiments = ['positive', 'negative', 'neutral', 'positive', 'neutral', 'neutral']\n",
    "\n",
    "# Create DataFrame\n",
    "df_reviews = pd.DataFrame({\n",
    "    'review': reviews,\n",
    "    'sentiment': sentiments\n",
    "})\n",
    "\n",
    "print(\"Original Reviews:\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in df_reviews.iterrows():\n",
    "    print(f\"\\n{idx+1}. [{row['sentiment'].upper()}]\")\n",
    "    print(f\"   {row['review']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before and After Preprocessing:\n",
      "================================================================================\n",
      "\n",
      "Review 1:\n",
      "Before: This movie was ABSOLUTELY AMAZING!!! Best film I've seen in years! #MustWatch\n",
      "After:  movie absolutely amazing best film see year\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Review 2:\n",
      "Before: Terrible waste of time... The acting was horrible and the plot made no sense whatsoever.\n",
      "After:  terrible waste time act horrible plot make sense whatsoever\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Review 3:\n",
      "Before: Pretty good overall, though the ending could've been better. I'd give it 7/10.\n",
      "After:  pretty good overall though end could well give\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Review 4:\n",
      "Before: OMG!!! @DirectorName you've outdone yourself! This is PERFECTION! https://moviereview.com/review\n",
      "After:  omg outdone perfection\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Review 5:\n",
      "Before: Not bad, not great. Just okay. Wouldn't watch it again but didn't hate it either.\n",
      "After:  bad great okay would watch hate either\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Review 6:\n",
      "Before: The cinematography was stunning! However, the storyline was quite predictable. Mixed feelings...\n",
      "After:  cinematography stun however storyline quite predictable mixed feeling\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing pipeline\n",
    "df_reviews['preprocessed'] = df_reviews['review'].apply(\n",
    "    lambda x: preprocess_text_pipeline(x, remove_numbers=True)\n",
    ")\n",
    "\n",
    "print(\"\\nBefore and After Preprocessing:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in df_reviews.iterrows():\n",
    "    print(f\"\\nReview {idx+1}:\")\n",
    "    print(f\"Before: {row['review']}\")\n",
    "    print(f\"After:  {row['preprocessed']}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Statistics:\n",
      "============================================================\n",
      "              Total tokens  Unique tokens  Avg tokens per review\n",
      "Original             108.0           75.0                   18.0\n",
      "Preprocessed          42.0           42.0                    7.0\n",
      "\n",
      "Reduction in unique tokens: 33 (44.0% decrease)\n"
     ]
    }
   ],
   "source": [
    "# Analyze vocabulary reduction\n",
    "\n",
    "# Get all tokens from original reviews\n",
    "original_tokens = []\n",
    "for review in df_reviews['review']:\n",
    "    original_tokens.extend(word_tokenize(review.lower()))\n",
    "\n",
    "# Get all tokens from preprocessed reviews\n",
    "preprocessed_tokens = []\n",
    "for review in df_reviews['preprocessed']:\n",
    "    preprocessed_tokens.extend(review.split())\n",
    "\n",
    "# Calculate statistics\n",
    "stats = {\n",
    "    'Original': {\n",
    "        'Total tokens': len(original_tokens),\n",
    "        'Unique tokens': len(set(original_tokens)),\n",
    "        'Avg tokens per review': len(original_tokens) / len(df_reviews)\n",
    "    },\n",
    "    'Preprocessed': {\n",
    "        'Total tokens': len(preprocessed_tokens),\n",
    "        'Unique tokens': len(set(preprocessed_tokens)),\n",
    "        'Avg tokens per review': len(preprocessed_tokens) / len(df_reviews)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display statistics\n",
    "print(\"Vocabulary Statistics:\")\n",
    "print(\"=\"*60)\n",
    "df_stats = pd.DataFrame(stats).T\n",
    "print(df_stats)\n",
    "\n",
    "print(f\"\\nReduction in unique tokens: {stats['Original']['Unique tokens'] - stats['Preprocessed']['Unique tokens']} \"\n",
    "      f\"({(1 - stats['Preprocessed']['Unique tokens']/stats['Original']['Unique tokens'])*100:.1f}% decrease)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Common Words:\n",
      "  movie: 1\n",
      "  absolutely: 1\n",
      "  amazing: 1\n",
      "  best: 1\n",
      "  film: 1\n",
      "  see: 1\n",
      "  year: 1\n",
      "  terrible: 1\n",
      "  waste: 1\n",
      "  time: 1\n",
      "  act: 1\n",
      "  horrible: 1\n",
      "  plot: 1\n",
      "  make: 1\n",
      "  sense: 1\n"
     ]
    }
   ],
   "source": [
    "# Visualize most common words\n",
    "\n",
    "# Count word frequencies\n",
    "word_freq = Counter(preprocessed_tokens)\n",
    "most_common = word_freq.most_common(15)\n",
    "\n",
    "# Create visualization\n",
    "words, frequencies = zip(*most_common)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(words, frequencies, color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Words', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 15 Most Frequent Words (After Preprocessing)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost Common Words:\")\n",
    "for word, freq in most_common:\n",
    "    print(f\"  {word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Best Practices <a id='best-practices'></a>\n",
    "\n",
    "### General Guidelines:\n",
    "\n",
    "1. **Understand Your Task**\n",
    "   - Different tasks need different preprocessing\n",
    "   - Sentiment analysis: Keep negations (\"not\", \"never\")\n",
    "   - Topic modeling: Aggressive preprocessing is okay\n",
    "   - Named Entity Recognition: Minimal preprocessing\n",
    "\n",
    "2. **Order Matters**\n",
    "   ```\n",
    "   Correct order:\n",
    "   1. Remove URLs, mentions\n",
    "   2. Lowercase\n",
    "   3. Tokenize\n",
    "   4. Remove punctuation\n",
    "   5. Remove stopwords\n",
    "   6. Stemming/Lemmatization\n",
    "   ```\n",
    "\n",
    "3. **Don't Over-preprocess**\n",
    "   - More preprocessing ≠ better results\n",
    "   - Can lose important information\n",
    "   - Test different configurations\n",
    "\n",
    "4. **Document Your Pipeline**\n",
    "   - Keep track of preprocessing steps\n",
    "   - Ensure reproducibility\n",
    "   - Version your preprocessing code\n",
    "\n",
    "5. **Consider Context**\n",
    "   - Domain-specific terms might look like errors\n",
    "   - Create custom stopword lists\n",
    "   - Preserve important symbols (e.g., $ for prices)\n",
    "\n",
    "### Common Mistakes to Avoid:\n",
    "\n",
    "❌ **Don't**: Remove all punctuation in sentiment analysis  \n",
    "✅ **Do**: Keep punctuation that affects meaning (!!!, ...)\n",
    "\n",
    "❌ **Don't**: Use aggressive stemming for production chatbots  \n",
    "✅ **Do**: Use lemmatization to maintain readability\n",
    "\n",
    "❌ **Don't**: Remove all numbers blindly  \n",
    "✅ **Do**: Consider if numbers are meaningful (prices, dates)\n",
    "\n",
    "❌ **Don't**: Apply same preprocessing to all languages  \n",
    "✅ **Do**: Use language-specific tools and stopwords\n",
    "\n",
    "❌ **Don't**: Lowercase everything for NER  \n",
    "✅ **Do**: Preserve case for proper nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "✅ **Basic Terminology**: Corpus, tokens, vocabulary, etc.  \n",
    "✅ **Tokenization**: Word, sentence, and custom tokenization  \n",
    "✅ **Text Normalization**: Lowercasing, removing special characters  \n",
    "✅ **Stemming**: Porter, Snowball, Lancaster stemmers  \n",
    "✅ **Lemmatization**: Dictionary-based normalization with POS tagging  \n",
    "✅ **Stopwords**: Removal and customization  \n",
    "✅ **Complete Pipeline**: End-to-end preprocessing function  \n",
    "✅ **Real-World Example**: Movie review preprocessing  \n",
    "✅ **Best Practices**: Guidelines for effective preprocessing\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Preprocessing is essential** but should be task-appropriate\n",
    "2. **Lemmatization > Stemming** for most modern applications\n",
    "3. **Custom pipelines** work better than one-size-fits-all\n",
    "4. **Experiment** with different configurations\n",
    "\n",
    "---\n",
    "\n",
    "**Next Notebook**: `02_Text_Representation.ipynb` - Convert preprocessed text into numerical features\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
